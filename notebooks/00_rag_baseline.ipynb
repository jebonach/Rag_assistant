{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d65fc778",
   "metadata": {},
   "source": [
    "# RAG baseline notebook\n",
    "\n",
    "This notebook is designed to run top-to-bottom without manual edits.\n",
    "\n",
    "How to run:\n",
    "1) Create venv and install requirements\n",
    "2) Copy `.env.example` -> `.env` and fill keys if you want LLM calls\n",
    "3) Restart kernel & Run all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61683a0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Config:\n",
    "    seed: int = int(os.getenv(\"SEED\", \"42\"))\n",
    "\n",
    "    # paths\n",
    "    project_dir: Path = Path(\"..\").resolve()\n",
    "    data_dir: Path = project_dir / \"data\"\n",
    "    indexes_dir: Path = project_dir / \"indexes\"\n",
    "    artifacts_dir: Path = project_dir / \"artifacts\"\n",
    "\n",
    "    # retrieval params (placeholders for now)\n",
    "    top_k: int = 5\n",
    "    chunk_size: int = 800\n",
    "    chunk_overlap: int = 150\n",
    "\n",
    "    txt_encoding: str = \"utf-8\"\n",
    "    search_mode: str = \"bm25\"  # bm25 | vector | hybrid\n",
    "\n",
    "    \n",
    "\n",
    "cfg = Config()\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefb2bf1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "env_path = cfg.project_dir / \".env\"\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "OPENAI_BASE_URL = os.getenv(\"OPENAI_BASE_URL\", \"\")\n",
    "CHAT_MODEL = os.getenv(\"CHAT_MODEL\", \"\")\n",
    "EMBEDDING_MODEL = os.getenv(\"EMBEDDING_MODEL\", \"\")\n",
    "\n",
    "llm_enabled = bool(OPENAI_API_KEY and (CHAT_MODEL or EMBEDDING_MODEL))\n",
    "print(\"llm_enabled:\", llm_enabled)\n",
    "print(\"CHAT_MODEL:\", CHAT_MODEL)\n",
    "print(\"EMBEDDING_MODEL:\", EMBEDDING_MODEL)\n",
    "print(\"OPENAI_BASE_URL:\", OPENAI_BASE_URL or \"(default)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e19964",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cfg.data_dir.mkdir(parents=True, exist_ok=True)\n",
    "cfg.indexes_dir.mkdir(parents=True, exist_ok=True)\n",
    "cfg.artifacts_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"project_dir:\", cfg.project_dir)\n",
    "print(\"data_dir:\", cfg.data_dir, \"exists:\", cfg.data_dir.exists())\n",
    "print(\"indexes_dir:\", cfg.indexes_dir, \"exists:\", cfg.indexes_dir.exists())\n",
    "print(\"artifacts_dir:\", cfg.artifacts_dir, \"exists:\", cfg.artifacts_dir.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c62c58b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.ingest import read_txt_pages, pages_to_rows\n",
    "\n",
    "txt_path = cfg.data_dir / \"book.txt\"\n",
    "pages = read_txt_pages(txt_path, encoding=cfg.txt_encoding)\n",
    "\n",
    "pages_df = pd.DataFrame(pages_to_rows(pages))\n",
    "pages_df.head(), len(pages_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ea968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_csv = cfg.artifacts_dir / \"pages.csv\"\n",
    "pages_df.to_csv(pages_csv, index=False)\n",
    "print(\"saved:\", pages_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd135f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.chunking import pages_to_page_chunks\n",
    "\n",
    "chunks = pages_to_page_chunks(\n",
    "    pages_df.to_dict(orient=\"records\"),\n",
    "    prefix=\"book\",\n",
    "    strict=True,\n",
    ")\n",
    "\n",
    "chunks_df = pd.DataFrame(chunks)\n",
    "chunks_df.head(), len(chunks_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db281a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.retrievers.bm25 import build_bm25_index, save_bm25\n",
    "\n",
    "bm25_index = build_bm25_index(chunks_df.to_dict(orient=\"records\"))\n",
    "bm25_path = cfg.indexes_dir / \"bm25.pkl\"\n",
    "save_bm25(bm25_index, bm25_path)\n",
    "print(\"saved:\", bm25_path)\n",
    "\n",
    "# demo queries\n",
    "for q in [\"что такое RAG\", \"индексация\", \"модель\"]:\n",
    "    hits = bm25_index.search(q, k=cfg.top_k)\n",
    "    print(\"\\nQUERY:\", q)\n",
    "    for h in hits:\n",
    "        print(f\"- score={h['score']:.4f} page={h['page']} chunk_id={h['chunk_id']}\")\n",
    "        print(\"  \", h[\"text\"][:180].replace(\"\\n\", \" \"), \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13e668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector / hybrid params\n",
    "vector_top_k: int = 5\n",
    "rrf_k: int = 60\n",
    "embed_batch_size: int = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eb7fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.embeddings import EmbeddingConfig\n",
    "from src.retrievers.vector_numpy import build_vector_index, embed_query, save_vector_index\n",
    "\n",
    "if not llm_enabled:\n",
    "    print(\"Vector index skipped: llm_enabled=False (no API key / model).\")\n",
    "else:\n",
    "    emb_cfg = EmbeddingConfig(\n",
    "        api_key=OPENAI_API_KEY,\n",
    "        base_url=OPENAI_BASE_URL or None,\n",
    "        model=EMBEDDING_MODEL,\n",
    "        batch_size=cfg.embed_batch_size,\n",
    "    )\n",
    "\n",
    "    vector_index = build_vector_index(chunks_df.to_dict(orient=\"records\"), emb_cfg)\n",
    "\n",
    "    vec_emb_path = cfg.indexes_dir / \"vector_embeddings.npy\"\n",
    "    vec_meta_path = cfg.indexes_dir / \"vector_meta.json\"\n",
    "    save_vector_index(vector_index, vec_emb_path, vec_meta_path)\n",
    "    print(\"saved:\", vec_emb_path)\n",
    "    print(\"saved:\", vec_meta_path)\n",
    "\n",
    "    for q in [\"пример запроса\", \"определение\", \"алгоритм\"]:\n",
    "        qv = embed_query(q, emb_cfg)\n",
    "        hits = vector_index.search(q, qv, k=cfg.vector_top_k)\n",
    "        print(\"\\nQUERY:\", q)\n",
    "        for h in hits:\n",
    "            print(f\"- score={h['score']:.4f} page={h['page']} chunk_id={h['chunk_id']}\")\n",
    "            print(\"  \", h[\"text\"][:180].replace(\"\\n\", \" \"), \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4e786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.retrievers.hybrid_rrf import rrf_fuse\n",
    "\n",
    "if not llm_enabled:\n",
    "    print(\"Hybrid skipped: llm_enabled=False.\")\n",
    "else:\n",
    "    for q in [\"пример запроса\", \"определение\", \"алгоритм\"]:\n",
    "        bm25_hits = bm25_index.search(q, k=cfg.top_k)\n",
    "        qv = embed_query(q, emb_cfg)\n",
    "        vec_hits = vector_index.search(q, qv, k=cfg.vector_top_k)\n",
    "\n",
    "        fused = rrf_fuse(bm25_hits=bm25_hits, vec_hits=vec_hits, k=cfg.top_k, rrf_k=cfg.rrf_k)\n",
    "\n",
    "        print(\"\\nQUERY:\", q)\n",
    "        for h in fused:\n",
    "            print(f\"- score_rrf={h['score_rrf']:.6f} page={h['page']} chunk_id={h['chunk_id']}\")\n",
    "            print(\"  \", h[\"text\"][:180].replace(\"\\n\", \" \"), \"...\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
